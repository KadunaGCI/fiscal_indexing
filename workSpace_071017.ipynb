{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip,os,tarfile,sys\n",
    "sys.path.append(os.pardir+'/src')\n",
    "from settings import *\n",
    "from boto3.session import Session\n",
    "import datetime\n",
    "import traceback\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import xml.etree.ElementTree as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# S3から記事データをダウンロードする関数\n",
    "def downloadFile(bucket, tag, target_day):\n",
    "    # バケットから指定されたタグと日付に該当するオブジェクトを取得\n",
    "    objects = bucket.objects.all().filter(Prefix=tag+target_day)\n",
    "\n",
    "    for object in objects:\n",
    "        # データを格納するパスを生成\n",
    "        path = os.path.join(DATA_DIR,tag+target_day)\n",
    "        # ダウンロードを実施\n",
    "        bucket.download_file(object.key, path)\n",
    "\n",
    "# startで指定された日付からspan日分のファイル名配列を生成\n",
    "def makeDateList(start, span):\n",
    "    dateList = []\n",
    "\n",
    "    for i in range(int(span)):\n",
    "        dateList.append('EID42168_' + start.strftime(\"%Y%m%d\") + '.xml.gz')\n",
    "        start = start + datetime.timedelta(days=1)\n",
    "\n",
    "    return dateList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# コマンドライン引数からダウンロードを開始する日付と範囲を取得\n",
    "start_date = '20150101'\n",
    "span = '365'\n",
    "start = datetime.datetime.strptime(start_date, '%Y%m%d')\n",
    "\n",
    "# S3へ接続\n",
    "session = Session(aws_access_key_id=AWS_ACCESS_KEY_ID,aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
    "s3 = session.resource('s3')\n",
    "bucket = s3.Bucket(BUCKET_NAME)\n",
    "\n",
    "# tagと日付リストを設定\n",
    "tag = \"EID42168_\"\n",
    "dateList = makeDateList(start, span)\n",
    "\n",
    "for date in dateList:\n",
    "    time = datetime.datetime.now()\n",
    "    date = date[9:]\n",
    "    try:\n",
    "        downloadFile(bucket, tag, date)\n",
    "        print(date + ' was done ' + str(datetime.datetime.now()-time))\n",
    "    except Exception as e:\n",
    "        print('error! ' + date)\n",
    "        print(logging.error(traceback.format_exc()))\n",
    "\n",
    "print('it taked ' + str(datetime.datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xml.gzファイルを解凍、xmlの構造を解析しCSVファイルを作成する関数\n",
    "def convertToCSV(file_name):\n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    # 引数として渡されたtar.gzファイルを解凍し、オープン\n",
    "    f = gzip.open(os.path.join(DATA_DIR,'originalData',file_name), 'r')\n",
    "\n",
    "    # CSVファイルのカラムに対応する配列を初期化\n",
    "    ids = []\n",
    "    headlines = []\n",
    "    timeofarrivals = []\n",
    "    bodys = []\n",
    "    #langs = []\n",
    "\n",
    "    # xmlを解析し、rootを取得\n",
    "    tree = et.parse(f)\n",
    "    elem = tree.getroot()\n",
    "    # エラーとなった記事をカウントする変数を初期化\n",
    "    fail_cnt = 0\n",
    "\n",
    "    # 解析したxmlから、記事単位で要素を取得\n",
    "    contents = elem.getiterator('ContentT')\n",
    "\n",
    "    for content in contents:\n",
    "        try:\n",
    "            # 記事の言語情報を取得し、日本語か英語の記事であれば以降の処理を実施\n",
    "            lang = content.find(\".//LanguageString\").text\n",
    "            #if lang == 'JAPANESE' or lang == 'ENGLISH':\n",
    "            if lang == 'JAPANESE':\n",
    "                if content.find(\".//Body\").text is not ' ':\n",
    "                    # 言語、ID、タイトル、タイムスタンプを配列に格納\n",
    "                    #langs.append(lang)\n",
    "                    ids.append(content.find(\".//Id/SUID\").text)\n",
    "                    headlines.append(content.find(\".//Headline\").text)\n",
    "                    timeofarrivals.append(content.find(\".//TimeOfArrival\").text)\n",
    "                    bodys.append(content.find(\".//Body\").text)\n",
    "        except:\n",
    "            # 読み取りに失敗した場合はカウント\n",
    "            fail_cnt += 1\n",
    "            #traceback.print_exc()\n",
    "    \n",
    "    print('fail_cnt:', fail_cnt)\n",
    "    \n",
    "    # カラムに対応する配列を用いてDataFrameを作成\n",
    "    df = DataFrame({\"Id\":ids})\n",
    "    df['Headline']=headlines\n",
    "    df['Body']=bodys\n",
    "    df['TimeOfArrival']=timeofarrivals\n",
    "    df.drop_duplicates()\n",
    "    # DataFrameをCSVファイルとして保存\n",
    "    df.to_csv(os.path.join(DATA_DIR,'csvData1',file_name.replace(\".xml.gz\",\".csv\")),encoding='utf8',index=False)\n",
    "    f.close()\n",
    "\n",
    "    print('file_name:' + file_name + ' time:' + str(datetime.datetime.now()-start) + ' record_count:' + str(len(df)) + ' fail_count:' + str(fail_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#　全ファイル取得\n",
    "files = os.listdir(DATA_DIR+'/originalData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataフォルダ配下の全ファイルを取得\n",
    "for i in range(0,len(files)):\n",
    "    convertToCSV(files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data解析　実験\n",
    "from janome.tokenizer import Tokenizer\n",
    "file_name = files[1]\n",
    "hoge = pd.read_csv(os.path.join(DATA_DIR,'csvData1',file_name.replace(\".xml.gz\",\".csv\")))\n",
    "headlines = hoge['Headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "安倍\t名詞,固有名詞,人名,姓,*,*,安倍,アベ,アベ\n",
      "晋\t名詞,固有名詞,人名,名,*,*,晋,ススム,ススム\n",
      "麻生\t名詞,固有名詞,人名,姓,*,*,麻生,アソウ,アソー\n",
      "太郎\t名詞,固有名詞,人名,名,*,*,太郎,タロウ,タロー\n",
      "中島\t名詞,固有名詞,人名,姓,*,*,中島,ナカジマ,ナカジマ\n",
      "悠太\t名詞,固有名詞,人名,名,*,*,悠太,ユウタ,ユータ\n",
      "ドナルド\t名詞,固有名詞,人名,名,*,*,ドナルド,ドナルド,ドナルド\n"
     ]
    }
   ],
   "source": [
    "# 使い方リマインド\n",
    "t = Tokenizer()\n",
    "#tokens = t.tokenize(headlines[0])\n",
    "tokens = t.tokenize('安倍晋三首相と、麻生太郎副総理兼財務相が、新たな「密約」を結んだという情報が飛び込んできた。中島悠太郎とドナルド・トランプは眠い')\n",
    "for token in tokens:\n",
    "    #print(token)\n",
    "    #if (token.part_of_speech.split(',')[0]=='名詞'):\n",
    "    if (token.part_of_speech.split(',')[2]=='人名'):\n",
    "        print(token)\n",
    "        #and token.part_of_speech.split(',')[1]=='固有名詞'):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = files[1]\n",
    "hoge = pd.read_csv(os.path.join(DATA_DIR,'csvData1',file_name.replace(\".xml.gz\",\".csv\"))).drop(['Id', 'Body', 'TimeOfArrival'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoge.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ＥＣＢのギリシャの銀行への緊急支援拡大にドイツが反対－ロイター</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ＥＣＢのギリシャの銀行への緊急支援拡大にドイツが反対－ロイター</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*日経平均始値は0.6％高の18103円98銭、ＴＯＰＩＸ0.8％高の1473.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>日本郵政グループは豪トール買収で合意－１株9.04豪ドルで</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*ブリヂストン株が買い気配</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Headline\n",
       "0             ＥＣＢのギリシャの銀行への緊急支援拡大にドイツが反対－ロイター\n",
       "1             ＥＣＢのギリシャの銀行への緊急支援拡大にドイツが反対－ロイター\n",
       "2  *日経平均始値は0.6％高の18103円98銭、ＴＯＰＩＸ0.8％高の1473.84\n",
       "3               日本郵政グループは豪トール買収で合意－１株9.04豪ドルで\n",
       "4                               *ブリヂストン株が買い気配"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "始\t名詞,固有名詞,人名,名,*,*,始,ハジメ,ハジメ\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "小林\t名詞,固有名詞,人名,姓,*,*,小林,コバヤシ,コバヤシ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "野村\t名詞,固有名詞,人名,姓,*,*,野村,ノムラ,ノムラ\n",
      "堀場\t名詞,固有名詞,人名,姓,*,*,堀場,ホリバ,ホリバ\n",
      "野村\t名詞,固有名詞,人名,姓,*,*,野村,ノムラ,ノムラ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "堀場\t名詞,固有名詞,人名,姓,*,*,堀場,ホリバ,ホリバ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "堀場\t名詞,固有名詞,人名,姓,*,*,堀場,ホリバ,ホリバ\n",
      "小林\t名詞,固有名詞,人名,姓,*,*,小林,コバヤシ,コバヤシ\n",
      "堀場\t名詞,固有名詞,人名,姓,*,*,堀場,ホリバ,ホリバ\n",
      "小林\t名詞,固有名詞,人名,姓,*,*,小林,コバヤシ,コバヤシ\n",
      "ルー\t名詞,固有名詞,人名,姓,*,*,ルー,ルー,ルー\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "フィッシャー\t名詞,固有名詞,人名,姓,*,*,フィッシャー,フィッシャー,フィッシャー\n",
      "安倍\t名詞,固有名詞,人名,姓,*,*,安倍,アベ,アベ\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "三村\t名詞,固有名詞,人名,姓,*,*,三村,ミツムラ,ミツムラ\n",
      "三村\t名詞,固有名詞,人名,姓,*,*,三村,ミツムラ,ミツムラ\n",
      "三村\t名詞,固有名詞,人名,姓,*,*,三村,ミツムラ,ミツムラ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "木内\t名詞,固有名詞,人名,姓,*,*,木内,キウチ,キウチ\n",
      "堀場\t名詞,固有名詞,人名,姓,*,*,堀場,ホリバ,ホリバ\n",
      "小林\t名詞,固有名詞,人名,姓,*,*,小林,コバヤシ,コバヤシ\n",
      "木内\t名詞,固有名詞,人名,姓,*,*,木内,キウチ,キウチ\n",
      "木内\t名詞,固有名詞,人名,姓,*,*,木内,キウチ,キウチ\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "木内\t名詞,固有名詞,人名,姓,*,*,木内,キウチ,キウチ\n",
      "フォックス\t名詞,固有名詞,人名,姓,*,*,フォックス,フォックス,フォックス\n",
      "堀場\t名詞,固有名詞,人名,姓,*,*,堀場,ホリバ,ホリバ\n",
      "堀場\t名詞,固有名詞,人名,姓,*,*,堀場,ホリバ,ホリバ\n",
      "建\t名詞,固有名詞,人名,姓,*,*,建,タテ,タテ\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "安倍\t名詞,固有名詞,人名,姓,*,*,安倍,アベ,アベ\n",
      "安倍\t名詞,固有名詞,人名,姓,*,*,安倍,アベ,アベ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "吉田\t名詞,固有名詞,人名,姓,*,*,吉田,ヨシダ,ヨシダ\n",
      "憲一郎\t名詞,固有名詞,人名,名,*,*,憲一郎,ケンイチロウ,ケンイチロー\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "ユニ\t名詞,固有名詞,人名,一般,*,*,ユニ,ユニ,ユニ\n",
      "安倍\t名詞,固有名詞,人名,姓,*,*,安倍,アベ,アベ\n",
      "吉田\t名詞,固有名詞,人名,姓,*,*,吉田,ヨシダ,ヨシダ\n",
      "憲一郎\t名詞,固有名詞,人名,名,*,*,憲一郎,ケンイチロウ,ケンイチロー\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "野村\t名詞,固有名詞,人名,姓,*,*,野村,ノムラ,ノムラ\n",
      "野村\t名詞,固有名詞,人名,姓,*,*,野村,ノムラ,ノムラ\n",
      "加藤\t名詞,固有名詞,人名,姓,*,*,加藤,カトウ,カトー\n",
      "加藤\t名詞,固有名詞,人名,姓,*,*,加藤,カトウ,カトー\n",
      "野村\t名詞,固有名詞,人名,姓,*,*,野村,ノムラ,ノムラ\n",
      "野村\t名詞,固有名詞,人名,姓,*,*,野村,ノムラ,ノムラ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "黒田\t名詞,固有名詞,人名,姓,*,*,黒田,クロダ,クロダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "野村\t名詞,固有名詞,人名,姓,*,*,野村,ノムラ,ノムラ\n",
      "李\t名詞,固有名詞,人名,姓,*,*,李,リ,リ\n",
      "李\t名詞,固有名詞,人名,姓,*,*,李,リ,リ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "甘利\t名詞,固有名詞,人名,姓,*,*,甘利,アマリ,アマリ\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "甘利\t名詞,固有名詞,人名,姓,*,*,甘利,アマリ,アマリ\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "甘利\t名詞,固有名詞,人名,姓,*,*,甘利,アマリ,アマリ\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "桐谷\t名詞,固有名詞,人名,姓,*,*,桐谷,キリタニ,キリタニ\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "アイン\t名詞,固有名詞,人名,姓,*,*,アイン,アイン,アイン\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "アイン\t名詞,固有名詞,人名,姓,*,*,アイン,アイン,アイン\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "アイン\t名詞,固有名詞,人名,姓,*,*,アイン,アイン,アイン\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "アイン\t名詞,固有名詞,人名,姓,*,*,アイン,アイン,アイン\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "アイン\t名詞,固有名詞,人名,姓,*,*,アイン,アイン,アイン\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "アイン\t名詞,固有名詞,人名,姓,*,*,アイン,アイン,アイン\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "アイン\t名詞,固有名詞,人名,姓,*,*,アイン,アイン,アイン\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "アイン\t名詞,固有名詞,人名,姓,*,*,アイン,アイン,アイン\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "トム\t名詞,固有名詞,人名,名,*,*,トム,トム,トム\n",
      "トム\t名詞,固有名詞,人名,名,*,*,トム,トム,トム\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "トール\t名詞,固有名詞,人名,姓,*,*,トール,トール,トール\n",
      "パウエル\t名詞,固有名詞,人名,姓,*,*,パウエル,パウエル,パウエル\n",
      "パウエル\t名詞,固有名詞,人名,姓,*,*,パウエル,パウエル,パウエル\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "アイン\t名詞,固有名詞,人名,姓,*,*,アイン,アイン,アイン\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "シラー\t名詞,固有名詞,人名,一般,*,*,シラー,シラー,シラー\n",
      "シラー\t名詞,固有名詞,人名,一般,*,*,シラー,シラー,シラー\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "住友\t名詞,固有名詞,人名,姓,*,*,住友,スミトモ,スミトモ\n",
      "シラー\t名詞,固有名詞,人名,一般,*,*,シラー,シラー,シラー\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "上田\t名詞,固有名詞,人名,姓,*,*,上田,ウエダ,ウエダ\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n",
      "秋野\t名詞,固有名詞,人名,姓,*,*,秋野,アキノ,アキノ\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "秋野\t名詞,固有名詞,人名,姓,*,*,秋野,アキノ,アキノ\n",
      "氏\t名詞,接尾,人名,*,*,*,氏,シ,シ\n",
      "シラー\t名詞,固有名詞,人名,一般,*,*,シラー,シラー,シラー\n",
      "シラー\t名詞,固有名詞,人名,一般,*,*,シラー,シラー,シラー\n",
      "モルガン\t名詞,固有名詞,人名,姓,*,*,モルガン,モルガン,モルガン\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "for i in range(0,hoge.shape[0]):\n",
    "    tokens = t.tokenize(hoge['Headline'][i])\n",
    "    for token in tokens:\n",
    "        #print(token)\n",
    "        #if (token.part_of_speech.split(',')[0]=='名詞'):\n",
    "        if (token.part_of_speech.split(',')[2]=='人名'):\n",
    "            print(token)\n",
    "            #and token.part_of_speech.split(',')[1]=='固有名詞'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hoge.stack().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.65454196929932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# just for measuring time\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# need to recieve unicode text, this is callable for TfidfVectorizer\n",
    "# need to recieve unicode text\n",
    "def myTokenizer(text):\n",
    "    #TARGET_CATEGORY = [\"名詞\", \"動詞\",  \"形容詞\", \"副詞\", \"連体詞\", \"助動詞\"]\n",
    "    #wordsIn=[]\n",
    "    #t = Tokenizer()\n",
    "    #tokens = t.tokenize(text)\n",
    "    #for token in tokens:\n",
    "    #    tokenCategory = token.part_of_speech.split(',')[0]\n",
    "    #    tokenBasic = token.base_form\n",
    "    #    if  (tokenCategory=='名詞' and token.part_of_speech.split(',')[1]=='固有名詞'):\n",
    "    #        wordsIn.append(token.surface)\n",
    "    #    elif tokenCategory in TARGET_CATEGORY:\n",
    "    #        if tokenBasic != '*':                               #if basic form can be defined\n",
    "    #            wordsIn.append(tokenBasic)\n",
    "    wordsIn=[]\n",
    "    t = Tokenizer()\n",
    "    tokens = t.tokenize(text)\n",
    "    for token in tokens:\n",
    "        #print(token)\n",
    "        #if (token.part_of_speech.split(',')[0]=='名詞'):\n",
    "        if (token.part_of_speech.split(',')[2]=='人名'):\n",
    "            wordsIn.append(token.surface)\n",
    "    return wordsIn\n",
    "\n",
    "\n",
    "#vectorizer = CountVectorizer(ngram_range=(1, 2),tokenizer=myTokenizer)     \n",
    "#tfidf_weighted_matrix = vectorizer.fit_transform(tweetsProcessed)\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2),tokenizer=myTokenizer,min_df=2).fit(hoge.stack().tolist()) # stop_words = ''\n",
    "bow = vectorizer.transform(hoge.stack().tolist())\n",
    "\n",
    "# for time\n",
    "elapsed_time = time.time() - start\n",
    "print(elapsed_time)\n",
    "print(\"bag_of_words with df as 2: {}\\n\".format(repr(bow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with highest tfidf: \n",
      "['アイン' '秋野 氏' '秋野' '甘利 氏' '甘利' '氏' '李' '木内' '憲一郎 氏' '憲一郎' '小林' '安倍' '堀場 小林'\n",
      " '堀場' '吉田 憲一郎' '吉田' '加藤' '住友 住友' '上田' '三村' 'モルガン 氏' 'モルガン' 'パウエル' 'トール'\n",
      " 'トム' 'シラー' 'アイン 氏' '野村' '黒田' '住友']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "max_value = bow.max(axis=0).toarray().ravel()\n",
    "sorted_by_num = max_value.argsort()\n",
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "print(\"Features with highest tfidf: \\n{}\\n\".format(\n",
    "      feature_names[sorted_by_num[-30:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 features:\n",
      "{'トール': 4, 'モルガン': 6, '小林': 18, '黒田': 29, '上田': 9, '野村': 28, '堀場': 15, '堀場 小林': 16, '安倍': 17, '三村': 8, '木内': 21, '吉田': 13, '憲一郎': 19, '氏': 23, '吉田 憲一郎': 14, '憲一郎 氏': 20, '加藤': 12, 'モルガン 氏': 7, '住友': 10, '李': 22, '甘利': 24, '甘利 氏': 25, 'アイン': 0, 'アイン 氏': 1, 'トム': 3, 'パウエル': 5, '住友 住友': 11, 'シラー': 2, '秋野': 26, '秋野 氏': 27}\n"
     ]
    }
   ],
   "source": [
    "print(\"First 30 features:\\n{}\".format(vectorizer.vocabulary_))?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('モルガン', 47), ('黒田', 32), ('氏', 29), ('上田', 21), ('住友', 20), ('トール', 18), ('アイン', 9), ('アイン 氏', 9), ('住友 住友', 9), ('野村', 7), ('堀場', 7), ('シラー', 5), ('小林', 4), ('安倍', 4), ('木内', 4), ('堀場 小林', 3), ('三村', 3), ('甘利', 3), ('甘利 氏', 3), ('吉田', 2), ('憲一郎', 2), ('吉田 憲一郎', 2), ('憲一郎 氏', 2), ('加藤', 2), ('モルガン 氏', 2), ('李', 2), ('トム', 2), ('パウエル', 2), ('秋野', 2), ('秋野 氏', 2)]\n"
     ]
    }
   ],
   "source": [
    "freqs = [(word, bow.getcol(idx).sum()) for word, idx in vectorizer.vocabulary_.items()]\n",
    "#sort from largest to smallest\n",
    "print (sorted (freqs, key = lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://labs.goo.ne.jp/api/jp/named-entity-extraction/\n",
    "# うまくいかないようであれば"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 図示にあたって"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime.strptime('20140101', '%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = makeDateList(start, '7')\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = datetime.datetime.strptime('20140201', '%Y%m%d')\n",
    "b = datetime.datetime.strptime('20140301', '%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a<b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# date:headlineのdictを受け取る\n",
    "# flagは、月=(month)か年(=year)か\n",
    "def shapeData(data, flag):\n",
    "    res = pd.DataFrame()\n",
    "    if (flag=='month'):\n",
    "        \n",
    "    elif(flag=='year'):\n",
    "        \n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
